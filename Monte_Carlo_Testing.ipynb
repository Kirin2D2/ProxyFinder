{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uWUQYLoYUZb"
      },
      "source": [
        "# Monte Carlo Testing for Proxy Finder Algorithm\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "CAwEOp8GYdEY"
      },
      "outputs": [],
      "source": [
        "from proxy_finder import *\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qOnUMZlYeqfW"
      },
      "source": [
        "# Stage 1: Testing Orthogonality Weight"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Steps:\n",
        "- Split YouGov dataset in half. Train_df and Test_df\n",
        "- Train model using Train_df with christian_nationalism as the target and the 17 predictors\n",
        "- Prepare Test_df by deleting christian_nationalism and adding several synthetic proxies with DIFFERENT levels of correlation with the target (in this case, CN)\n",
        "- Call generate proxies function with many levels of ortho_weights and see at which weights are these synthetic proxies chosen"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "wIImp49Se3XQ"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(df, target):\n",
        "  # split dataset in half\n",
        "  df_train = df.sample(frac=0.5, random_state=42)\n",
        "  df_test = df.drop(df_train.index)\n",
        "\n",
        "  # add synthetic proxies to test set\n",
        "  target_column = df_test[target]\n",
        "  synthetic_proxies = generate_synthetic_proxies(target_column)\n",
        "  for name, proxy in synthetic_proxies.items():\n",
        "    df_test[name] = proxy\n",
        "\n",
        "  # drop target from test set\n",
        "  df_test = df_test.drop(columns=[target])\n",
        "\n",
        "  return df_train, df_test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def generate_synthetic_proxies(target_column, target_correlations=[0.95, 0.9, 0.8, 0.7], noise_level=0.1):\n",
        "   # Convert target_column to numpy array and standardize\n",
        "    target = np.array(target_column)\n",
        "    target = (target - np.mean(target)) / np.std(target)\n",
        "\n",
        "    synthetic_proxies = {}\n",
        "    for corr in target_correlations:\n",
        "        # Generate independent standard normal variable\n",
        "        z = np.random.standard_normal(len(target))\n",
        "\n",
        "        # Create correlated variable using the correlation formula\n",
        "        proxy = corr * target + np.sqrt(1 - corr**2) * z\n",
        "\n",
        "        # Add controlled noise\n",
        "        proxy = proxy + np.random.normal(0, noise_level, len(target))\n",
        "\n",
        "        # Standardize final proxy\n",
        "        proxy = (proxy - np.mean(proxy)) / np.std(proxy)\n",
        "\n",
        "        synthetic_proxies[f'proxy_{corr:.2f}'] = proxy\n",
        "\n",
        "    return synthetic_proxies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Running the Monte Carlo Simulations\n",
        "df = pd.read_stata(\"/content/temp_yougov.dta\")\n",
        "weights = [0.45, 0.47, 0.49, 0.51, 0.53, 0.55, 0.57, 0.59, 0.61, 0.63, 0.65, 0.67, 0.69, 0.71]\n",
        "num_iterations = 5\n",
        "target = 'christian_nationalism'\n",
        "predictors = [\n",
        "                   'presvote20post',\n",
        "                   'housevote20post',\n",
        "                   'senvote20post',\n",
        "                   'pff_jb',\n",
        "                   'pff_dt',\n",
        "                   'pid7',\n",
        "                   'election_fairnness',\n",
        "                   'educ',\n",
        "                   'hispanic',\n",
        "                   'partisan_violence',\n",
        "                   'immigrant_citizenship',\n",
        "                   'immigrant_deport',\n",
        "                   'auth_grid_1',\n",
        "                   'auth_grid_3',\n",
        "                   'auth_grid_2',\n",
        "                   'faminc_new']\n",
        "\n",
        "df_train, df_test = prepare_dataset(df, target)\n",
        "selection_tracker = {orth_weight: {} for orth_weight in weights}\n",
        "\n",
        "for orth_weight in weights:\n",
        "  print(f\"Testing with orthogonality weight: {orth_weight}\")\n",
        "\n",
        "  for i in range(num_iterations):\n",
        "    print(f\"Running iteration {i+1}/{num_iterations}\")\n",
        "    top_proxies = proxy_finder(df_train=df_train, df_test=df_test, target=target, predictors=predictors, num_proxies=5, orth_weight=orth_weight, orthogonal_vars=predictors)\n",
        "\n",
        "    for rank, proxy in enumerate(top_proxies, 1):\n",
        "          # Update selection counter for top pick\n",
        "      if rank == 1:\n",
        "        selection_tracker[orth_weight][proxy] = selection_tracker[orth_weight].get(proxy, 0) + 1\n",
        "\n",
        "# Visualize results\n",
        "results = []\n",
        "for orth_weight, proxies in selection_tracker.items():\n",
        "    for proxy, frequency in proxies.items():\n",
        "        results.append({'orth_weight': orth_weight, 'proxy': proxy, 'frequency': (frequency / num_iterations) * 100})\n",
        "\n",
        "results_df = pd.DataFrame(results)\n",
        "pivot_data = results_df.pivot(index='orth_weight', columns='proxy', values='frequency')\n",
        "\n",
        "# Create the line plot\n",
        "plt.figure(figsize=(10, 6))\n",
        "\n",
        "# Plot each proxy as a separate line\n",
        "plt.plot(pivot_data.index, pivot_data['proxy_0.95'], marker='o', label='proxy_0.95', linewidth=2)\n",
        "plt.plot(pivot_data.index, pivot_data['proxy_0.90'], marker='o', label='proxy_0.90', linewidth=2)\n",
        "plt.plot(pivot_data.index, pivot_data['proxy_0.80'], marker='o', label='proxy_0.80', linewidth=2)\n",
        "\n",
        "\n",
        "# Customize the plot\n",
        "plt.xlabel('Orthogonal Weight')\n",
        "plt.ylabel('Frequency')\n",
        "plt.ylim(0, 100)\n",
        "plt.title('Proxy Frequency vs Orthogonal Weight')\n",
        "plt.grid(True, linestyle='--', alpha=0.7)\n",
        "plt.legend()\n",
        "\n",
        "# Show the plot\n",
        "plt.show()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
