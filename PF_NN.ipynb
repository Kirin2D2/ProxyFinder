{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09485737",
   "metadata": {},
   "source": [
    "# version of proxyFinder algorithm using neural network to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d1e34881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import statsmodels.api as sm\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "91825a81",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PYTHONPATH: None\n",
      "PATH: c:\\Users\\kirin\\anaconda3\\envs\\torchenv;C:\\Users\\kirin\\anaconda3\\envs\\torchenv;C:\\Users\\kirin\\anaconda3\\envs\\torchenv\\Library\\mingw-w64\\bin;C:\\Users\\kirin\\anaconda3\\envs\\torchenv\\Library\\usr\\bin;C:\\Users\\kirin\\anaconda3\\envs\\torchenv\\Library\\bin;C:\\Users\\kirin\\anaconda3\\envs\\torchenv\\Scripts;C:\\Users\\kirin\\anaconda3\\envs\\torchenv\\bin;C:\\Users\\kirin\\anaconda3\\condabin;C:\\Program Files\\Git\\usr\\local\\bin;C:\\Program Files\\Git\\bin;C:\\Program Files\\Eclipse Adoptium\\jdk-11.0.15.10-hotspot\\bin;C:\\Program Files (x86)\\Common Files\\Oracle\\Java\\javapath;C:\\Windows\\system32;C:\\Windows;C:\\Windows\\System32\\Wbem;C:\\Windows\\System32\\WindowsPowerShell\\v1.0;C:\\Windows\\System32\\OpenSSH;C:\\Program Files (x86)\\NVIDIA Corporation\\PhysX\\Common;C:\\Program Files\\NVIDIA Corporation\\NVIDIA NvDLISR;C:\\WINDOWS\\system32;C:\\WINDOWS;C:\\WINDOWS\\System32\\Wbem;C:\\WINDOWS\\System32\\WindowsPowerShell\\v1.0;C:\\WINDOWS\\System32\\OpenSSH;C:\\Program Files\\Git\\cmd;C:\\Users\\kirin\\AppData\\Local\\Microsoft\\WindowsApps;C:\\Users\\kirin\\AppData\\Local\\Programs\\MiKTeX\\miktex\\bin\\x64;C:\\Users\\kirin\\AppData\\Local\\Programs\\Microsoft VS Code\\bin\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "print(\"PYTHONPATH:\", os.environ.get('PYTHONPATH'))\n",
    "print(\"PATH:\", os.environ.get('PATH'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b535aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proxy_finder_validate(item, candidates, df1, df2, predictors, orthogonal_vars):\n",
    "\n",
    "    # validate proxies and st item\n",
    "    assert item in df1.columns, f'AssertionError: item {item} not in df1.columns'\n",
    "\n",
    "    assert predictors, f'AssertionError: missing predictors'\n",
    "    \n",
    "    for c in predictors:\n",
    "        assert c in df1.columns, f'AssertionError: predictor {c} not in df1.columns'\n",
    "        assert c in df2.columns, f'AssertionError: predictor {c} not in df2.columns' # only because we need same variable in second dataset        \n",
    "    \n",
    "    for c in candidates:\n",
    "        assert c in df2.columns, f'AssertionError: candidate {c} not in df2.columns'\n",
    "        \n",
    "    if (orthogonal_vars != None):\n",
    "        for c in orthogonal_vars:\n",
    "            assert c in df2.columns, f'AssertionError: orthogonal variable {c} not in df2.columns'\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28ebb647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a new df that is a copy of df, with: rescale all columns to be between 0 and 1, inclusive. Drop any non-numeric columns.\n",
    "def data_rescale(df):\n",
    "    df = df.copy() # preserve immutability\n",
    "\n",
    "    # Select only the numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    \n",
    "    # Initialize the scaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Fit the scaler to the data and transform it\n",
    "    scaled_values = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "    # Create a new DataFrame with the scaled values, maintaining the original column names\n",
    "    scaled_df = pd.DataFrame(scaled_values, columns=numeric_cols, index=df.index)\n",
    "    \n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d017725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network definition\n",
    "def build_nn_model(input_dim):\n",
    "    model = Sequential([\n",
    "        Dense(64, activation='relu', input_shape=(input_dim,)),\n",
    "        Dropout(0.5),  # Adding dropout regularization\n",
    "        Dense(32, activation='relu'),\n",
    "        Dropout(0.5),  # Adding dropout regularization\n",
    "        Dense(1)\n",
    "    ])\n",
    "    model.compile(optimizer='adam', loss='mse')\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ff982100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a trained neural network to predict df[item] using df[predictors_df1]\n",
    "# report error and crash if predictors don't predict item\n",
    "def train_nn_model(X_train, y_train, input_dim, epochs=100):\n",
    "    model = build_nn_model(input_dim)\n",
    "    model.fit(X_train, y_train, epochs=epochs, validation_split=0.2, verbose=0)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bb532362",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 64)                704       \n",
      "                                                                 \n",
      " dropout_10 (Dropout)        (None, 64)                0         \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 32)                2080      \n",
      "                                                                 \n",
      " dropout_11 (Dropout)        (None, 32)                0         \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 1)                 33        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 2,817\n",
      "Trainable params: 2,817\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "7/7 [==============================] - 0s 2ms/step - loss: 0.1063\n",
      "Test loss: 0.10631357878446579\n",
      "7/7 [==============================] - 0s 1ms/step\n",
      "Predictions: [[0.37851167]\n",
      " [0.33828557]\n",
      " [0.3574198 ]\n",
      " [0.3896603 ]\n",
      " [0.36884052]\n",
      " [0.43611443]\n",
      " [0.4647947 ]\n",
      " [0.4247344 ]\n",
      " [0.38919306]\n",
      " [0.34760493]]\n"
     ]
    }
   ],
   "source": [
    " #DEBUG#### test nn train and build -- appear to be working\n",
    "# Function to create synthetic data for testing\n",
    "def create_synthetic_data(num_samples=1000, num_features=10):\n",
    "    np.random.seed(42)\n",
    "    X = np.random.rand(num_samples, num_features)\n",
    "    y = np.random.rand(num_samples)\n",
    "    return X, y\n",
    "\n",
    "# Create synthetic data\n",
    "X, y = create_synthetic_data()\n",
    "\n",
    "# Normalize the data\n",
    "scaler = MinMaxScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train the neural network\n",
    "input_dim = X_train.shape[1]\n",
    "model = train_nn_model(X_train, y_train, input_dim, epochs=10)\n",
    "\n",
    "# Print model summary\n",
    "print(model.summary())\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "loss = model.evaluate(X_test, y_test)\n",
    "print(f\"Test loss: {loss}\")\n",
    "\n",
    "# Predict on the test set\n",
    "predictions = model.predict(X_test)\n",
    "print(f\"Predictions: {predictions[:10]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a775aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get predictions from the neural network\n",
    "def get_nn_predictions(df_train, df_test, predictors, target, epochs=100):\n",
    "    # Remove rows with NaN values in predictor columns\n",
    "    df_train = df_train.dropna(subset=predictors)\n",
    "    df_test = df_test.dropna(subset=predictors)\n",
    "    \n",
    "    X_train = df_train[predictors].to_numpy()\n",
    "    y_train = df_train[target].to_numpy()\n",
    "    X_test = df_test[predictors].to_numpy()\n",
    "\n",
    "\n",
    "    model = train_nn_model(X_train, y_train, len(predictors), epochs)\n",
    "    predictions = model.predict(X_test)\n",
    "    print(f\"Predictions before flattening: {predictions[:10]}\") #DEBUG\n",
    "    print('predictions after flattening: ', predictions.flatten()[:10])#DEBUG\n",
    "\n",
    "    return predictions.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b1b4e6ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7/7 [==============================] - 0s 1ms/step\n",
      "Predictions before flattening: [[0.3332389 ]\n",
      " [0.34358305]\n",
      " [0.4043013 ]\n",
      " [0.36761525]\n",
      " [0.41573027]\n",
      " [0.42988393]\n",
      " [0.3725268 ]\n",
      " [0.42518765]\n",
      " [0.33807346]\n",
      " [0.33562624]]\n",
      "predictions after flattening:  [0.3332389  0.34358305 0.4043013  0.36761525 0.41573027 0.42988393\n",
      " 0.3725268  0.42518765 0.33807346 0.33562624]\n",
      "Predicted scores: [0.3332389  0.34358305 0.4043013  0.36761525 0.41573027 0.42988393\n",
      " 0.3725268  0.42518765 0.33807346 0.33562624]\n"
     ]
    }
   ],
   "source": [
    "# Create synthetic data#DEBUG\n",
    "X, y = create_synthetic_data(num_samples=1000, num_features=10)\n",
    "\n",
    "# Convert synthetic data to DataFrame\n",
    "columns = [f'feature_{i}' for i in range(X.shape[1])]\n",
    "df = pd.DataFrame(X, columns=columns)\n",
    "df['target'] = y\n",
    "\n",
    "# Normalize the data\n",
    "df = data_rescale(df)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "df_train, df_test = train_test_split(df, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define predictors and target\n",
    "predictors = [f'feature_{i}' for i in range(X.shape[1])]\n",
    "target = 'target'\n",
    "\n",
    "# Test get_nn_predictions function\n",
    "predicted_scores = get_nn_predictions(df_train, df_test, predictors, target, epochs=10)\n",
    "\n",
    "# Print results\n",
    "print(f\"Predicted scores: {predicted_scores[:10]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "acfe4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proxy_finder(df_train, df_test, target, predictors, num_proxies=1, orth_weight=0.5, candidates=None, orthogonal_vars=None):\n",
    "    if candidates is None:\n",
    "        candidates = list(df_test.select_dtypes(include='number').columns)\n",
    "    \n",
    "    print(f\"Predictors: {predictors}\") #DEBUGDEBUGDEBUG------------------------------------------------------------\n",
    "    print(f\"Candidates: {candidates}\")\n",
    "\n",
    "    # Predict status threat scores in df_test\n",
    "    df_train = data_rescale(df_train)\n",
    "    df_test = data_rescale(df_test)\n",
    "    print(df_train.head)\n",
    "    print(df_test.head)\n",
    "    predicted_scores = get_nn_predictions(df_train, df_test, predictors, target)\n",
    "    \n",
    "    df_test['predicted_status_threat'] = predicted_scores\n",
    "    print(f\"Predicted scores: {predicted_scores[:10]}\")  #DEBUG DEBUG------------------------------------------------------------ \n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    for c in candidates:\n",
    "        candset = df_test[[c, 'predicted_status_threat']].copy().dropna()\n",
    "        if candset.empty:\n",
    "            continue\n",
    "        \n",
    "        pred_scores = candset['predicted_status_threat']\n",
    "        candcol = candset[c]\n",
    "\n",
    "        X_pred = sm.add_constant(candcol)\n",
    "        model_pred = sm.OLS(pred_scores, X_pred).fit()\n",
    "        results[c] = {\n",
    "            'R_squared': model_pred.rsquared,\n",
    "            'p_value': model_pred.pvalues[1],\n",
    "            'coef': model_pred.params[1]\n",
    "        }\n",
    "        print(f\"candidate {c}: Results: {results}\")  # Debug statement------------------------------------------------------------ \n",
    "  \n",
    "    best_proxies = []\n",
    "\n",
    "    if orthogonal_vars:\n",
    "        orth_score = {}\n",
    "        for c in candidates:\n",
    "            candset = df_test[[c, 'predicted_status_threat']].copy().dropna()\n",
    "            pred_scores = candset['predicted_status_threat']\n",
    "            candcol = candset[c]\n",
    "        \n",
    "            X = sm.add_constant(candcol)\n",
    "            temp_orth_scores = []\n",
    "            for orth_var in orthogonal_vars:\n",
    "                orthset = df_test[[orth_var]].copy().dropna()\n",
    "                common_indices = candset.index.intersection(orthset.index)\n",
    "                if common_indices.empty:\n",
    "                    continue\n",
    "                orth_col = orthset.loc[common_indices, orth_var]\n",
    "                candcol_common = candset.loc[common_indices, c]\n",
    "\n",
    "                X_common = sm.add_constant(candcol_common)\n",
    "                model = sm.OLS(orth_col, X_common).fit()\n",
    "                temp_orth_scores.append(model.rsquared)\n",
    "            \n",
    "            if temp_orth_scores:\n",
    "                orth_score[c] = sum(temp_orth_scores) / len(temp_orth_scores)\n",
    "            else:\n",
    "                orth_score[c] = 0\n",
    "        \n",
    "        proxy_scores = {}\n",
    "        for c in candidates:\n",
    "            try:\n",
    "                proxy_scores[c] = (c, (1 - orth_weight) * results[c]['R_squared'] - orth_weight * orth_score[c])\n",
    "            except KeyError as e:\n",
    "                continue\n",
    "        \n",
    "        sorted_results = sorted(proxy_scores.values(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        for i in range(min(num_proxies, len(sorted_results))):\n",
    "            proxy, score = sorted_results[i]\n",
    "            best_proxies.append(proxy)\n",
    "            print(f\"Proxy {i+1} for {target}: {proxy} with score: {score}\")\n",
    "    else: \n",
    "        sorted_results = sorted(results.items(), key=lambda x: (-x[1]['R_squared'], x[1]['p_value']))\n",
    "    \n",
    "        for i in range(min(num_proxies, len(sorted_results))):\n",
    "            proxy, metrics = sorted_results[i]\n",
    "            best_proxies.append(proxy)\n",
    "            print(f\"Proxy {i+1} for {target}: {proxy} with R_squared: {metrics['R_squared']} and p_value: {metrics['p_value']}\")\n",
    "    \n",
    "    return best_proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f09aff0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictors: ['psc1_W1_01', 'christian_nationalism', 'authoritarianism']\n",
      "Candidates: ['vendor_W3', 'immigrant_W3', 'inputstate_W3', 'votereg_W3', 'inputregstate_W3', 'birthyr_W3', 'age5_W3', 'gender_W3', 'transgender_W3', 'educ_W3', 'educ4_W3', 'educ2_W3', 'race_W3', 'race4_W3', 'race3_W3', 'race2_W3', 'hispanic_W3', 'hispanic_origin_1_W3', 'hispanic_origin_2_W3', 'hispanic_origin_3_W3', 'hispanic_origin_4_W3', 'turnout20post_W3', 'presvote20post_W3', 'faminc_new_W3', 'res_region_W3', 'res_division_W3', 'reg_region_W3', 'reg_division_W3', 'partisanship_W3', 'partisanship_reps_W3', 'partisanship_dems_W3', 'partisanship_ind_W3', 'house2022_W3', 'biden_approval_W3', 'trump_approval_W3', 'expandinghouse_split_W3', 'expandinghouse_A_W3', 'expandinghouse_B_W3', 'expandinghouse_C_W3', 'expandinghouse_D_W3', 'electioninteg_split_W3', 'electioninteg_A_W3', 'electioninteg_B_W3', 'electioninteg_C_W3', 'pres2024_W3', 'jan6_exposure_W3', 'jan6_hearings_W3', 'trump_crimes_W3', 'trump_charge_W3', 'trump_office_W3', 'racial_identity_W3', 'antiracism_opposition_1_W3', 'antiracism_opposition_2_W3', 'antiracism_opposition_3_W3', 'antiracism_opposition_4_W3', 'antiracism_opposition_5_W3', 'antiracism_opposition_6_W3', 'antiracism_opposition_7_W3', 'crt_W3', 'ethnicworry_W3', 'race_therm_black_W3', 'race_therm_white_W3', 'race_therm_hisp_W3', 'maga_views_W3', 'roe_W3', 'partisan_violence_W3', 'partisan_violence_kill_W3', 'opp_threat_W3', 'replacement_W3', 'status_threat_1_W3', 'status_threat_2_W3', 'status_threat_3_W3', 'status_threat_4_W3', 'status_threat_5_W3', 'status_threat_6_W3', 'status_threat_7_W3', 'status_threat_8_W3', 'psc_grid_1_W3', 'psc_grid_2_W3', 'psc_grid_3_W3', 'psc_grid_4_W3', 'psc_grid_5_W3', 'psc_grid_6_W3', 'psc_grid_7_W3', 'psc_grid_8_W3', 'attentioncheck_1_W3', 'attentioncheck_2_W3', 'attentioncheck_3_W3', 'attentioncheck_4_W3', 'attentioncheck_5_W3', 'sdo_grid_1_W3', 'sdo_grid_2_W3', 'sdo_grid_3_W3', 'sdo_grid_4_W3', 'sdo_grid_5_W3', 'sdo_grid_6_W3', 'christian_nationalism_1_W3', 'christian_nationalism_2_W3', 'christian_nationalism_3_W3', 'christian_nationalism_4_W3', 'christian_nationalism_5_W3', 'christian_nationalism_6_W3', 'hardworkingvlazy_W3', 'pronenot_violence_W3', 'covid_leaders_1_W3', 'covid_leaders_2_W3', 'covid_leaders_3_W3', 'covid_theories_1_W3', 'covid_theories_2_W3', 'covid_theories_3_W3', 'covid_theories_4_W3', 'covid_theories_5_W3', 'sample_W3', 'respondent_id', 'weight_W3', 'weight2_W3', 'weight3_W3', 'vendor_W2', 'immigrant_W2', 'inputstate_W2', 'votereg_W2', 'inputregstate_W2', 'birthyr_W2', 'age5_W2', 'gender_W2', 'transgender_W2', 'educ_W2', 'educ4_W2', 'educ2_W2', 'race_W2', 'race4_W2', 'race3_W2', 'race2_W2', 'hispanic_W2', 'hispanic_origin_1_W2', 'hispanic_origin_2_W2', 'hispanic_origin_3_W2', 'hispanic_origin_4_W2', 'turnout20post_W2', 'presvote20post_W2', 'res_region_W2', 'res_division_W2', 'reg_region_W2', 'reg_division_W2', 'partisanship_W2', 'partisanship_reps_W2', 'partisanship_dems_W2', 'partisanship_ind_W2', 'pres2024_W2', 'cab_split_W2', 'cab_a_W2', 'cab_b_W2', 'dd_split_W2', 'q_dd_a_W2', 'q_dd_b_W2', 'bidenapp_W2', 'ec_split_W2', 'ec_a_W2', 'ec_b_W2', 'demtoday_W2', 'stratfac_reps_W2', 'stratfac_dems_W2', 'winner2020_W2', 'roevwade_W2', 'race_therm_black_W2', 'race_therm_white_W2', 'race_therm_hisp_W2', 'racial_id_W2', 'group_disc_black_W2', 'group_disc_white_W2', 'group_disc_hisp_W2', 'wc_jobs_W2', 'wc_together_W2', 'wc_influence_W2', 'wc_min_split_W2', 'white_min_W2', 'christian_min_W2', 'proudboys_W2', 'threeperc_W2', 'teaparty_W2', 'qanon_W2', 'maga_W2', 'oathkeepers_W2', 'psc_st_rotation_W2', 'psc1_W2', 'psc2_W2', 'psc3_W2', 'psc4_W2', 'psc5_W2', 'psc6_W2', 'psc7_W2', 'psc8_W2', 'st1_W2', 'st2_W2', 'st3_W2', 'st4_W2', 'st5_W2', 'st6_W2', 'st7_W2', 'st8_W2', 'coup_W2', 'violence_fistfights_W2', 'attentioncheck_1_W2', 'attentioncheck_2_W2', 'attentioncheck_3_W2', 'attentioncheck_4_W2', 'attentioncheck_5_W2', 'violence_damage_W2', 'violence_kill_W2', 'pg1_W2', 'pg2_W2', 'pg3_W2', 'pg4_W2', 'pg5_W2', 'ap1_W2', 'ap2_W2', 'ap3_W2', 'ap4_W2', 'rr1_W2', 'rr2_W2', 'rr3_W2', 'rr4_W2', 'rr5_W2', 'rr6_W2', 'rr7_W2', 'rr8_W2', 'racekilling_cops_W2', 'racekilling_civs_W2', 'hardworkingvlazy_W2', 'pronenot_violence_W2', 'regres1_W2', 'regres2_W2', 'regres3_W2', 'l1_W2', 'l2_W2', 'l3_W2', 'l4_W2', 'l5_W2', 'l6_W2', 'l7_W2', 'l8_W2', 'l9_W2', 'l11_W2', 'l12_W2', 'l13_W2', 'l14_W2', 'l15_W2', 'l16_W2', 'l17_W2', 'l18_W2', 'flag_W2', 'vg_split_W2', 'violent_group_a_W2', 'violent_group_b_W2', 'sample_W2', 'weight_W2', 'weight2_W2', 'weight3_W2', 'vendor', 'immigrant', 'inputstate', 'votereg', 'inputregstate', 'birthyr', 'age5', 'gender', 'transgender', 'educ', 'educ4', 'educ2', 'race', 'race4', 'race3', 'race2', 'hispanic', 'hispanic_origin_1', 'hispanic_origin_2', 'hispanic_origin_3', 'hispanic_origin_4', 'turnout20post', 'presvote20post', 'res_region', 'res_division', 'reg_region', 'reg_division', 'newsint', 'faminc_new', 'anychild', 'app_biden', 'child18', 'employ', 'ideo5', 'marstat', 'track', 'pid3', 'pid7', 'ideo7', 'turnout16prim', 'presvote16postprim', 'turnout16', 'presvote16post', 'turnout20prim', 'presvote20postprim', 'senvote20post', 'housevote20post', 'presvote24', 'mwe_split', 'mwe_a', 'mwe_ethnic', 'mwe_b', 'checks_and_balances', 'strong_leader', 'biden_presidential_approval', 'trump_presidential_approval', 'election_fairnness', 'winner_2020', 'gerrymandering_experiment_split', 'gerrymandering_experiment_a', 'gerrymandering_experiment_b', 'critial_race_theory', 'pff_dt', 'pff_mm', 'pff_jb', 'pff_np', 'pff_rp', 'pff_dp', 'capitol_riot', 'prosecute_rioters', 'frf_tbb', 'frf_t3p', 'frf_ttp', 'frf_qs', 'frf_maga', 'maga_views', 'reactionary_movements_split', 'el_reqall', 'el_eipv', 'el_arv', 'el_felon', 'el_cit_vbm', 'electoral_college', 'abortion', 'roe', 'immigrant_citizenship', 'immigrant_deport', 'mask_mandate', 'racial_identity', 'white_conscious_split', 'white_conscious_a', 'white_conscious_b', 'group_discrim_grid_1', 'group_discrim_grid_2', 'group_discrim_grid_3', 'race_resent_grid_1', 'race_resent_grid_2', 'race_resent_grid_3', 'race_resent_grid_4', 'stat_threat_grid_1', 'stat_threat_grid_2', 'stat_threat_grid_3', 'stat_threat_grid_4', 'stat_threat_grid_5', 'stat_threat_grid_6', 'stat_threat_grid_7', 'stat_threat_grid_8', 'para_social_grid_1', 'para_social_grid_2', 'para_social_grid_3', 'para_social_grid_4', 'para_social_grid_5', 'para_social_grid_6', 'para_social_grid_7', 'para_social_grid_8', 'attn1_1', 'attn1_2', 'attn1_3', 'attn1_4', 'attn1_5', 'auth_grid_1', 'auth_grid_2', 'auth_grid_3', 'amb_sexism_grid_1', 'amb_sexism_grid_2', 'amb_sexism_grid_3', 'soc_dom_grid_1', 'soc_dom_grid_2', 'soc_dom_grid_3', 'race_animus_grid_1', 'race_animus_grid_2', 'race_animus_grid_3', 'race_animus_grid_4', 'race_animus_grid_5', 'race_animus_grid_6', 'race_animus_grid_7', 'christ_nat_grid_1', 'christ_nat_grid_2', 'christ_nat_grid_3', 'christ_nat_grid_4', 'trait_agg_grid_1', 'trait_agg_grid_2', 'trait_agg_grid_3', 'trait_agg_grid_4', 'part_soc_dist', 'partisan_violence', 'partisan_fistfights', 'partisan_damage', 'partisan_kill', 'civil_war', 'threat_oppose', 'threat_own', 'weight', '_w1_w2merge', '_w1_w2_w3merge', 'st_W1', 'st_W1_01', 'status_W2', 'status2_W2', 'psc1_W1', 'psc1_W1_01', 'cn1', 'cn2', 'cn3', 'cn4', 'cn5', 'cn6', 'cn_W2', 'cn1_W2', 'rr_W1', 'rr1_W1', 'rrx_W1', 'auth_W1', 'auth1_W1', 'socdom_W1', 'socdom1_W1', 'christn', 'christn1', 'ill_W2', 'illib_W2', 'christian_top', 'age501', 'education', 'party_ID', 'ideology', 'christian_nationalism', 'white_top', 'status_threat', 'socdom2_W1', 'SDO11', 'social_dom11', 'race_resent', 'authoritarianism', 'bidenfav', 'trumpfav', 'mwe_ethnic_01', 'white_infl1', 'black_discrim_1', 'hisp_discrim_1', 'white_discrim_1', 'critrace', 'critrace1', 'cap_riot', 'pros_riot', 'imm_cit', 'imm_dep', 'race_ID1', 'civilw', 'whitecon_a', 'whitecon_b', 'maga_view', 'pres2024', 'stat_W3', 'sta_W3_01', 'pid17_W2', 'pid17_W3', 'pid01_W3', 'pid01_W2', 'race_ID2', 'race_ID3', 'sdo6', 'sdo601', 'imm_dep1', 'white', 'medinc', 'male', 'white2']\n",
      "<bound method NDFrame.head of       vendor_W3  immigrant_W3  inputstate_W3  votereg_W3  inputregstate_W3  \\\n",
      "0           0.0          1.00       0.636364         0.0          0.357143   \n",
      "1           0.0          0.75       0.272727         0.0          0.153061   \n",
      "2           0.0          0.75       0.509091         0.0          0.285714   \n",
      "3           0.0          0.75       0.090909         0.0          0.051020   \n",
      "4           0.0          1.00       0.727273         0.0          0.408163   \n",
      "...         ...           ...            ...         ...               ...   \n",
      "3395        NaN           NaN            NaN         NaN               NaN   \n",
      "3396        NaN           NaN            NaN         NaN               NaN   \n",
      "3397        NaN           NaN            NaN         NaN               NaN   \n",
      "3398        NaN           NaN            NaN         NaN               NaN   \n",
      "3399        NaN           NaN            NaN         NaN               NaN   \n",
      "\n",
      "      birthyr_W3  age5_W3  gender_W3  transgender_W3  educ_W3  ...  pid01_W2  \\\n",
      "0       0.351351      1.0   0.333333             0.5      1.0  ...       NaN   \n",
      "1       0.216216      1.0   0.333333             0.5      0.8  ...       NaN   \n",
      "2       0.013514      1.0   0.333333             0.5      0.4  ...  0.000000   \n",
      "3       0.081081      1.0   0.333333             0.5      1.0  ...       NaN   \n",
      "4       0.297297      1.0   0.333333             0.5      0.4  ...  1.000000   \n",
      "...          ...      ...        ...             ...      ...  ...       ...   \n",
      "3395         NaN      NaN        NaN             NaN      NaN  ...  0.166667   \n",
      "3396         NaN      NaN        NaN             NaN      NaN  ...  1.000000   \n",
      "3397         NaN      NaN        NaN             NaN      NaN  ...  0.666667   \n",
      "3398         NaN      NaN        NaN             NaN      NaN  ...  0.166667   \n",
      "3399         NaN      NaN        NaN             NaN      NaN  ...  1.000000   \n",
      "\n",
      "      race_ID2  race_ID3      sdo6    sdo601  imm_dep1  white  medinc  male  \\\n",
      "0          NaN      0.50  0.000000  0.000000       NaN    NaN     1.0   NaN   \n",
      "1         0.00      0.00  0.166667  0.166667  0.000000    1.0     1.0   0.0   \n",
      "2         0.25      0.50  0.333333  0.333333  0.166667    1.0     0.0   0.0   \n",
      "3          NaN      0.75  0.000000  0.000000       NaN    NaN     1.0   NaN   \n",
      "4         0.00      0.00  0.500000  0.500000  1.000000    1.0     1.0   0.0   \n",
      "...        ...       ...       ...       ...       ...    ...     ...   ...   \n",
      "3395      0.25       NaN       NaN       NaN       NaN    NaN     1.0   NaN   \n",
      "3396      0.00       NaN       NaN       NaN       NaN    NaN     1.0   NaN   \n",
      "3397      0.00       NaN       NaN       NaN       NaN    NaN     1.0   NaN   \n",
      "3398      1.00       NaN       NaN       NaN       NaN    NaN     1.0   NaN   \n",
      "3399      0.50       NaN       NaN       NaN       NaN    NaN     1.0   NaN   \n",
      "\n",
      "      white2  \n",
      "0        NaN  \n",
      "1        1.0  \n",
      "2        1.0  \n",
      "3        NaN  \n",
      "4        1.0  \n",
      "...      ...  \n",
      "3395     NaN  \n",
      "3396     NaN  \n",
      "3397     NaN  \n",
      "3398     NaN  \n",
      "3399     NaN  \n",
      "\n",
      "[3400 rows x 485 columns]>\n",
      "<bound method NDFrame.head of       vendor_W3  immigrant_W3  inputstate_W3  votereg_W3  inputregstate_W3  \\\n",
      "0           0.0          1.00       0.636364         0.0          0.357143   \n",
      "1           0.0          0.75       0.272727         0.0          0.153061   \n",
      "2           0.0          0.75       0.509091         0.0          0.285714   \n",
      "3           0.0          0.75       0.090909         0.0          0.051020   \n",
      "4           0.0          1.00       0.727273         0.0          0.408163   \n",
      "...         ...           ...            ...         ...               ...   \n",
      "3395        NaN           NaN            NaN         NaN               NaN   \n",
      "3396        NaN           NaN            NaN         NaN               NaN   \n",
      "3397        NaN           NaN            NaN         NaN               NaN   \n",
      "3398        NaN           NaN            NaN         NaN               NaN   \n",
      "3399        NaN           NaN            NaN         NaN               NaN   \n",
      "\n",
      "      birthyr_W3  age5_W3  gender_W3  transgender_W3  educ_W3  ...  pid01_W2  \\\n",
      "0       0.351351      1.0   0.333333             0.5      1.0  ...       NaN   \n",
      "1       0.216216      1.0   0.333333             0.5      0.8  ...       NaN   \n",
      "2       0.013514      1.0   0.333333             0.5      0.4  ...  0.000000   \n",
      "3       0.081081      1.0   0.333333             0.5      1.0  ...       NaN   \n",
      "4       0.297297      1.0   0.333333             0.5      0.4  ...  1.000000   \n",
      "...          ...      ...        ...             ...      ...  ...       ...   \n",
      "3395         NaN      NaN        NaN             NaN      NaN  ...  0.166667   \n",
      "3396         NaN      NaN        NaN             NaN      NaN  ...  1.000000   \n",
      "3397         NaN      NaN        NaN             NaN      NaN  ...  0.666667   \n",
      "3398         NaN      NaN        NaN             NaN      NaN  ...  0.166667   \n",
      "3399         NaN      NaN        NaN             NaN      NaN  ...  1.000000   \n",
      "\n",
      "      race_ID2  race_ID3      sdo6    sdo601  imm_dep1  white  medinc  male  \\\n",
      "0          NaN      0.50  0.000000  0.000000       NaN    NaN     1.0   NaN   \n",
      "1         0.00      0.00  0.166667  0.166667  0.000000    1.0     1.0   0.0   \n",
      "2         0.25      0.50  0.333333  0.333333  0.166667    1.0     0.0   0.0   \n",
      "3          NaN      0.75  0.000000  0.000000       NaN    NaN     1.0   NaN   \n",
      "4         0.00      0.00  0.500000  0.500000  1.000000    1.0     1.0   0.0   \n",
      "...        ...       ...       ...       ...       ...    ...     ...   ...   \n",
      "3395      0.25       NaN       NaN       NaN       NaN    NaN     1.0   NaN   \n",
      "3396      0.00       NaN       NaN       NaN       NaN    NaN     1.0   NaN   \n",
      "3397      0.00       NaN       NaN       NaN       NaN    NaN     1.0   NaN   \n",
      "3398      1.00       NaN       NaN       NaN       NaN    NaN     1.0   NaN   \n",
      "3399      0.50       NaN       NaN       NaN       NaN    NaN     1.0   NaN   \n",
      "\n",
      "      white2  \n",
      "0        NaN  \n",
      "1        1.0  \n",
      "2        1.0  \n",
      "3        NaN  \n",
      "4        1.0  \n",
      "...      ...  \n",
      "3395     NaN  \n",
      "3396     NaN  \n",
      "3397     NaN  \n",
      "3398     NaN  \n",
      "3399     NaN  \n",
      "\n",
      "[3400 rows x 485 columns]>\n",
      "41/41 [==============================] - 0s 1ms/step\n",
      "Predictions before flattening: [[0.35582864]\n",
      " [0.32820454]\n",
      " [0.7007251 ]\n",
      " [0.2749105 ]\n",
      " [0.3367984 ]\n",
      " [0.3308413 ]\n",
      " [0.40920645]\n",
      " [0.5151774 ]\n",
      " [0.66371256]\n",
      " [0.6277706 ]]\n",
      "predictions after flattening:  [0.35582864 0.32820454 0.7007251  0.2749105  0.3367984  0.3308413\n",
      " 0.40920645 0.5151774  0.66371256 0.6277706 ]\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Length of values (1285) does not match length of index (3400)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[35], line 13\u001b[0m\n\u001b[0;32m      8\u001b[0m predictors \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpsc1_W1_01\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchristian_nationalism\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthoritarianism\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Predictors in both training and testing sets\u001b[39;00m\n\u001b[0;32m     11\u001b[0m orthogonal_vars \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthoritarianism\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchristian_nationalism\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_dom11\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrace_resent\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparty_ID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mideology\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 13\u001b[0m best_proxies \u001b[38;5;241m=\u001b[39m \u001b[43mproxy_finder\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf_test\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredictors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_proxies\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43morthogonal_vars\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43morthogonal_vars\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(best_proxies)\n",
      "Cell \u001b[1;32mIn[32], line 15\u001b[0m, in \u001b[0;36mproxy_finder\u001b[1;34m(df_train, df_test, target, predictors, num_proxies, orth_weight, candidates, orthogonal_vars)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mprint\u001b[39m(df_test\u001b[38;5;241m.\u001b[39mhead)\n\u001b[0;32m     13\u001b[0m predicted_scores \u001b[38;5;241m=\u001b[39m get_nn_predictions(df_train, df_test, predictors, target)\n\u001b[1;32m---> 15\u001b[0m \u001b[43mdf_test\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredicted_status_threat\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m \u001b[38;5;241m=\u001b[39m predicted_scores\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted scores: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpredicted_scores[:\u001b[38;5;241m10\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)  \u001b[38;5;66;03m#DEBUG DEBUG------------------------------------------------------------ \u001b[39;00m\n\u001b[0;32m     18\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n",
      "File \u001b[1;32mc:\\Users\\kirin\\anaconda3\\envs\\torchenv\\lib\\site-packages\\pandas\\core\\frame.py:4311\u001b[0m, in \u001b[0;36mDataFrame.__setitem__\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4308\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_setitem_array([key], value)\n\u001b[0;32m   4309\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   4310\u001b[0m     \u001b[38;5;66;03m# set column\u001b[39;00m\n\u001b[1;32m-> 4311\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_set_item\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\kirin\\anaconda3\\envs\\torchenv\\lib\\site-packages\\pandas\\core\\frame.py:4524\u001b[0m, in \u001b[0;36mDataFrame._set_item\u001b[1;34m(self, key, value)\u001b[0m\n\u001b[0;32m   4514\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_set_item\u001b[39m(\u001b[38;5;28mself\u001b[39m, key, value) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   4515\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4516\u001b[0m \u001b[38;5;124;03m    Add series to DataFrame in specified column.\u001b[39;00m\n\u001b[0;32m   4517\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4522\u001b[0m \u001b[38;5;124;03m    ensure homogeneity.\u001b[39;00m\n\u001b[0;32m   4523\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 4524\u001b[0m     value, refs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sanitize_column\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   4526\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   4527\u001b[0m         key \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\n\u001b[0;32m   4528\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mndim \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   4529\u001b[0m         \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value\u001b[38;5;241m.\u001b[39mdtype, ExtensionDtype)\n\u001b[0;32m   4530\u001b[0m     ):\n\u001b[0;32m   4531\u001b[0m         \u001b[38;5;66;03m# broadcast across multiple columns if necessary\u001b[39;00m\n\u001b[0;32m   4532\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns\u001b[38;5;241m.\u001b[39mis_unique \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcolumns, MultiIndex):\n",
      "File \u001b[1;32mc:\\Users\\kirin\\anaconda3\\envs\\torchenv\\lib\\site-packages\\pandas\\core\\frame.py:5266\u001b[0m, in \u001b[0;36mDataFrame._sanitize_column\u001b[1;34m(self, value)\u001b[0m\n\u001b[0;32m   5263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _reindex_for_setitem(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex)\n\u001b[0;32m   5265\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_list_like(value):\n\u001b[1;32m-> 5266\u001b[0m     \u001b[43mcom\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequire_length_match\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   5267\u001b[0m arr \u001b[38;5;241m=\u001b[39m sanitize_array(value, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindex, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, allow_2d\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m   5268\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[0;32m   5269\u001b[0m     \u001b[38;5;28misinstance\u001b[39m(value, Index)\n\u001b[0;32m   5270\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m value\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mobject\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   5273\u001b[0m     \u001b[38;5;66;03m# TODO: Remove kludge in sanitize_array for string mode when enforcing\u001b[39;00m\n\u001b[0;32m   5274\u001b[0m     \u001b[38;5;66;03m# this deprecation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\kirin\\anaconda3\\envs\\torchenv\\lib\\site-packages\\pandas\\core\\common.py:573\u001b[0m, in \u001b[0;36mrequire_length_match\u001b[1;34m(data, index)\u001b[0m\n\u001b[0;32m    569\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    570\u001b[0m \u001b[38;5;124;03mCheck the length of data matches the length of the index.\u001b[39;00m\n\u001b[0;32m    571\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    572\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data) \u001b[38;5;241m!=\u001b[39m \u001b[38;5;28mlen\u001b[39m(index):\n\u001b[1;32m--> 573\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    574\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLength of values \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    575\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m) \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    576\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdoes not match length of index \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    577\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m(\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(index)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    578\u001b[0m     )\n",
      "\u001b[1;31mValueError\u001b[0m: Length of values (1285) does not match length of index (3400)"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "datafile_train =  r'C:\\Users\\kirin\\Downloads\\W1_W2_W3_Merged_saved.dta'\n",
    "datafile_test =  r'C:\\Users\\kirin\\Downloads\\W1_W2_W3_Merged_saved.dta'\n",
    "df_train = pd.read_stata(datafile_train, convert_categoricals=False)\n",
    "df_test = pd.read_stata(datafile_test, convert_categoricals=False)\n",
    "\n",
    "target = 'status_threat'  # The target variable in the training set\n",
    "predictors = ['psc1_W1_01',\n",
    "                   'christian_nationalism',\n",
    "                   'authoritarianism']  # Predictors in both training and testing sets\n",
    "orthogonal_vars = ['authoritarianism', 'christian_nationalism', 'social_dom11', 'race_resent', 'party_ID', 'ideology']\n",
    "\n",
    "best_proxies = proxy_finder(df_train, df_test, target, predictors, num_proxies=5, orthogonal_vars=orthogonal_vars)\n",
    "print(best_proxies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python (torchenv)",
   "language": "python",
   "name": "torchenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
