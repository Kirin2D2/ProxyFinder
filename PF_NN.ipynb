{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09485737",
   "metadata": {},
   "source": [
    "# version of proxyFinder algorithm using neural network to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d1e34881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import statsmodels.api as sm\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "fedb758c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import tqdm\n",
    "import os\n",
    "from torchviz import make_dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d017725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network definition\n",
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.layer1 = nn.Linear(input_dim, 64)\n",
    "        self.layer2 = nn.Linear(64, 32)\n",
    "        self.layer3 = nn.Linear(32, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = torch.relu(self.layer1(x))\n",
    "        x = torch.relu(self.layer2(x))\n",
    "        x = self.layer3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "4b535aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proxy_finder_validate(item, candidates, df1, df2, predictors, orthogonal_vars):\n",
    "\n",
    "    # validate proxies and st item\n",
    "    assert item in df1.columns, f'AssertionError: item {item} not in df1.columns'\n",
    "\n",
    "    assert predictors, f'AssertionError: missing predictors'\n",
    "    \n",
    "    for c in predictors:\n",
    "        assert c in df1.columns, f'AssertionError: predictor {c} not in df1.columns'\n",
    "        assert c in df2.columns, f'AssertionError: predictor {c} not in df2.columns' # only because we need same variable in second dataset        \n",
    "    \n",
    "    for c in candidates:\n",
    "        assert c in df2.columns, f'AssertionError: candidate {c} not in df2.columns'\n",
    "        \n",
    "    if (orthogonal_vars != None):\n",
    "        for c in orthogonal_vars:\n",
    "            assert c in df2.columns, f'AssertionError: orthogonal variable {c} not in df2.columns'\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "28ebb647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale all columns to be between 0 and 1, inclusive. Drop any non-numeric columns.\n",
    "def data_rescale(df):\n",
    "   \n",
    "    # Select only the numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    \n",
    "    # Initialize the scaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Fit the scaler to the data and transform it\n",
    "    scaled_values = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "    # Create a new DataFrame with the scaled values, maintaining the original column names\n",
    "    scaled_df = pd.DataFrame(scaled_values, columns=numeric_cols, index=df.index)\n",
    "    \n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "ff982100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a trained neural network to predict df[item] using df[predictors_df1]\n",
    "# report error and crash if predictors don't predict item\n",
    "def train_nn_model(X_train, y_train, input_dim, epochs=100):\n",
    "    model = SimpleNN(input_dim)\n",
    "    criterion = nn.MSELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "    X_train_tensor = torch.tensor(X_train, dtype=torch.float32)\n",
    "    y_train_tensor = torch.tensor(y_train, dtype=torch.float32).view(-1, 1)\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "a775aa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to get predictions from the neural network\n",
    "def get_nn_predictions(df_train, df_test, predictors, target, epochs=100):\n",
    "    X_train = df_train[predictors].to_numpy()\n",
    "    y_train = df_train[target].to_numpy()\n",
    "    X_test = df_test[predictors].to_numpy()\n",
    "\n",
    "    model = train_nn_model(X_train, y_train, len(predictors), epochs)\n",
    "\n",
    "    model.eval()\n",
    "    X_test_tensor = torch.tensor(X_test, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        predictions = model(X_test_tensor).cpu().numpy()\n",
    "\n",
    "    return predictions.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "acfe4965",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to find the best proxies\n",
    "def proxy_finder(df_train, df_test, target, predictors, num_proxies=1, orth_weight=0.5, candidates=None, orthogonal_vars=None):\n",
    "    if candidates is None:\n",
    "        candidates = list(df_test.select_dtypes(include='number').columns)\n",
    "    \n",
    "    # Predict status threat scores in df_test\n",
    "    df_train = data_rescale(df_train)\n",
    "    df_test = data_rescale(df_test)\n",
    "    predicted_scores = get_nn_predictions(df_train, df_test, predictors, target)\n",
    "    \n",
    "    df_test['predicted_status_threat'] = predicted_scores\n",
    "\n",
    "    results = {}\n",
    "    \n",
    "    for c in candidates:\n",
    "        candset = df_test[[c, 'predicted_status_threat']].copy().dropna()\n",
    "        if candset.empty:\n",
    "            continue\n",
    "        \n",
    "        pred_scores = candset['predicted_status_threat']\n",
    "        candcol = candset[c]\n",
    "\n",
    "        X_pred = sm.add_constant(candcol)\n",
    "        model_pred = sm.OLS(pred_scores, X_pred).fit()\n",
    "        results[c] = {\n",
    "            'R_squared': model_pred.rsquared,\n",
    "            'p_value': model_pred.pvalues[1],\n",
    "            'coef': model_pred.params[1]\n",
    "        }\n",
    "  \n",
    "    best_proxies = []\n",
    "\n",
    "    if orthogonal_vars:\n",
    "        orth_score = {}\n",
    "        for c in candidates:\n",
    "            candset = df_test[[c, 'predicted_status_threat']].copy().dropna()\n",
    "            pred_scores = candset['predicted_status_threat']\n",
    "            candcol = candset[c]\n",
    "        \n",
    "            X = sm.add_constant(candcol)\n",
    "            temp_orth_scores = []\n",
    "            for orth_var in orthogonal_vars:\n",
    "                orthset = df_test[[orth_var]].copy().dropna()\n",
    "                common_indices = candset.index.intersection(orthset.index)\n",
    "                if common_indices.empty:\n",
    "                    continue\n",
    "                orth_col = orthset.loc[common_indices, orth_var]\n",
    "                candcol_common = candset.loc[common_indices, c]\n",
    "\n",
    "                X_common = sm.add_constant(candcol_common)\n",
    "                model = sm.OLS(orth_col, X_common).fit()\n",
    "                temp_orth_scores.append(model.rsquared)\n",
    "            \n",
    "            if temp_orth_scores:\n",
    "                orth_score[c] = sum(temp_orth_scores) / len(temp_orth_scores)\n",
    "            else:\n",
    "                orth_score[c] = 0\n",
    "        \n",
    "        proxy_scores = {}\n",
    "        for c in candidates:\n",
    "            try:\n",
    "                proxy_scores[c] = (c, (1 - orth_weight) * results[c]['R_squared'] - orth_weight * orth_score[c])\n",
    "            except KeyError as e:\n",
    "                continue\n",
    "        \n",
    "        sorted_results = sorted(proxy_scores.values(), key=lambda x: x[1], reverse=True)\n",
    "        \n",
    "        for i in range(min(num_proxies, len(sorted_results))):\n",
    "            proxy, score = sorted_results[i]\n",
    "            best_proxies.append(proxy)\n",
    "            print(f\"Proxy {i+1} for {target}: {proxy} with score: {score}\")\n",
    "    else: \n",
    "        sorted_results = sorted(results.items(), key=lambda x: (-x[1]['R_squared'], x[1]['p_value']))\n",
    "    \n",
    "        for i in range(min(num_proxies, len(sorted_results))):\n",
    "            proxy, metrics = sorted_results[i]\n",
    "            best_proxies.append(proxy)\n",
    "            print(f\"Proxy {i+1} for {target}: {proxy} with R_squared: {metrics['R_squared']} and p_value: {metrics['p_value']}\")\n",
    "    \n",
    "    return best_proxies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "f09aff0f",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Numpy is not available",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[95], line 13\u001b[0m\n\u001b[0;32m      8\u001b[0m predictors \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpsc1_W1_01\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m      9\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchristian_nationalism\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m     10\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthoritarianism\u001b[39m\u001b[38;5;124m'\u001b[39m]  \u001b[38;5;66;03m# Predictors in both training and testing sets\u001b[39;00m\n\u001b[0;32m     11\u001b[0m orthogonal_vars \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauthoritarianism\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mchristian_nationalism\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msocial_dom11\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrace_resent\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mparty_ID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mideology\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m---> 13\u001b[0m best_proxies \u001b[38;5;241m=\u001b[39m proxy_finder(df_train, df_test, target, predictors, num_proxies\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m5\u001b[39m, orthogonal_vars\u001b[38;5;241m=\u001b[39morthogonal_vars)\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28mprint\u001b[39m(best_proxies)\n",
      "Cell \u001b[1;32mIn[94], line 9\u001b[0m, in \u001b[0;36mproxy_finder\u001b[1;34m(df_train, df_test, target, predictors, num_proxies, orth_weight, candidates, orthogonal_vars)\u001b[0m\n\u001b[0;32m      7\u001b[0m df_train \u001b[38;5;241m=\u001b[39m data_rescale(df_train)\n\u001b[0;32m      8\u001b[0m df_test \u001b[38;5;241m=\u001b[39m data_rescale(df_test)\n\u001b[1;32m----> 9\u001b[0m predicted_scores \u001b[38;5;241m=\u001b[39m get_nn_predictions(df_train, df_test, predictors, target)\n\u001b[0;32m     11\u001b[0m df_test[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpredicted_status_threat\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m predicted_scores\n\u001b[0;32m     13\u001b[0m results \u001b[38;5;241m=\u001b[39m {}\n",
      "Cell \u001b[1;32mIn[93], line 12\u001b[0m, in \u001b[0;36mget_nn_predictions\u001b[1;34m(df_train, df_test, predictors, target, epochs)\u001b[0m\n\u001b[0;32m     10\u001b[0m X_test_tensor \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtensor(X_test, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mfloat32)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m---> 12\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m model(X_test_tensor)\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n\u001b[0;32m     14\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\u001b[38;5;241m.\u001b[39mflatten()\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Numpy is not available"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "datafile_train =  r'C:\\Users\\kirin\\Downloads\\W1_W2_W3_Merged_saved.dta'\n",
    "datafile_test =  r'C:\\Users\\kirin\\Downloads\\W1_W2_W3_Merged_saved.dta'\n",
    "df_train = pd.read_stata(datafile_train, convert_categoricals=False)\n",
    "df_test = pd.read_stata(datafile_test, convert_categoricals=False)\n",
    "\n",
    "target = 'status_threat'  # The target variable in the training set\n",
    "predictors = ['psc1_W1_01',\n",
    "                   'christian_nationalism',\n",
    "                   'authoritarianism']  # Predictors in both training and testing sets\n",
    "orthogonal_vars = ['authoritarianism', 'christian_nationalism', 'social_dom11', 'race_resent', 'party_ID', 'ideology']\n",
    "\n",
    "best_proxies = proxy_finder(df_train, df_test, target, predictors, num_proxies=5, orthogonal_vars=orthogonal_vars)\n",
    "print(best_proxies)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
