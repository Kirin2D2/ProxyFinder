{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "09485737",
   "metadata": {},
   "source": [
    "# version of proxyFinder algorithm using neural network to make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d1e34881",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import statsmodels.api as sm\n",
    "from sklearn import datasets, linear_model\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fedb758c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\kirin\\anaconda3\\Lib\\site-packages\\torch\\nested\\_internal\\nested_tensor.py:417: UserWarning: Failed to initialize NumPy: \n",
      "\n",
      "IMPORTANT: PLEASE READ THIS FOR ADVICE ON HOW TO SOLVE THIS ISSUE!\n",
      "\n",
      "Importing the numpy C-extensions failed. This error can happen for\n",
      "many reasons, often due to issues with your setup or how NumPy was\n",
      "installed.\n",
      "\n",
      "We have compiled some common reasons and troubleshooting tips at:\n",
      "\n",
      "    https://numpy.org/devdocs/user/troubleshooting-importerror.html\n",
      "\n",
      "Please note and check the following:\n",
      "\n",
      "  * The Python version is: Python3.11 from \"c:\\Users\\kirin\\anaconda3\\python.exe\"\n",
      "  * The NumPy version is: \"1.24.3\"\n",
      "\n",
      "and make sure that they are the versions you expect.\n",
      "Please carefully study the documentation linked above for further help.\n",
      "\n",
      "Original error was: DLL load failed while importing _multiarray_umath: The specified module could not be found.\n",
      " (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_numpy.cpp:84.)\n",
      "  values=torch.randn(3, 3, device=\"meta\"),\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cpu\n"
     ]
    }
   ],
   "source": [
    "# Setting some hyperparameters and making sure we have a GPU\n",
    "%matplotlib inline\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import random\n",
    "import tqdm\n",
    "import os\n",
    "from torchviz import make_dot\n",
    "\n",
    "# Set the device to use\n",
    "device = torch.device(\"cpu\")\n",
    "\n",
    "# If you'd like to use a GPU instead of a CPU to run the following code, you can uncomment the following line\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "## Hyperparameters\n",
    "num_epochs = 10\n",
    "batch_size = 256\n",
    "\n",
    "## Fixing Random Seed for Reproducibility\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)\n",
    "random.seed(0)\n",
    "\n",
    "\n",
    "# This line prints out the type of device you will run the notebook in.\n",
    "print(str(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4b535aad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def proxy_finder_validate(item, candidates, df1, df2, predictors, orthogonal_vars):\n",
    "\n",
    "    # validate proxies and st item\n",
    "    assert item in df1.columns, f'AssertionError: item {item} not in df1.columns'\n",
    "\n",
    "    assert predictors, f'AssertionError: missing predictors'\n",
    "    \n",
    "    for c in predictors:\n",
    "        assert c in df1.columns, f'AssertionError: predictor {c} not in df1.columns'\n",
    "        assert c in df2.columns, f'AssertionError: predictor {c} not in df2.columns' # only because we need same variable in second dataset        \n",
    "    \n",
    "    for c in candidates:\n",
    "        assert c in df2.columns, f'AssertionError: candidate {c} not in df2.columns'\n",
    "        \n",
    "    if (orthogonal_vars != None):\n",
    "        for c in orthogonal_vars:\n",
    "            assert c in df2.columns, f'AssertionError: orthogonal variable {c} not in df2.columns'\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "28ebb647",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rescale all columns to be between 0 and 1, inclusive. Drop any non-numeric columns.\n",
    "def data_rescale(df):\n",
    "   \n",
    "    # Select only the numeric columns\n",
    "    numeric_cols = df.select_dtypes(include=['number']).columns\n",
    "    \n",
    "    # Initialize the scaler\n",
    "    scaler = MinMaxScaler()\n",
    "\n",
    "    # Fit the scaler to the data and transform it\n",
    "    scaled_values = scaler.fit_transform(df[numeric_cols])\n",
    "\n",
    "    # Create a new DataFrame with the scaled values, maintaining the original column names\n",
    "    scaled_df = pd.DataFrame(scaled_values, columns=numeric_cols, index=df.index)\n",
    "    \n",
    "    return scaled_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff982100",
   "metadata": {},
   "outputs": [],
   "source": [
    "# return a trained neural network to predict df[item] using df[predictors_df1]\n",
    "# report error and crash if predictors don't predict item\n",
    "def get_model(predictors_df1, item, test_pct, df):\n",
    "\n",
    "    # create linear model such that item_predicted = B0 + B1X1 + ... + BnXn\n",
    "    prepped_data = df[predictors_df1 + [item]].dropna(axis=0)\n",
    "    X = prepped_data[predictors_df1].to_numpy()\n",
    "\n",
    "    y = prepped_data[item].to_numpy()\n",
    "\n",
    "\n",
    "    #split into train and test data\n",
    "\n",
    "    test_size = (int) (X.shape[0] * test_pct)\n",
    "    train_size = (int) (X.shape[0] * (1-test_pct))\n",
    "\n",
    "    x_train = X[:-train_size]\n",
    "    x_test = X[-test_size:]\n",
    "\n",
    "    # Split the targets into training/testing sets\n",
    "    y_train = y[:-train_size]\n",
    "    y_test = y[-test_size:]\n",
    "\n",
    "\n",
    "    # run linear regression\n",
    "  \n",
    "    \n",
    "    if (mean_squared_error(regr.predict(x_test), y_test) > 0.02):\n",
    "        print('Input Error: Predictors cannot predict item in df1')\n",
    "        print('Aborting program')\n",
    "        sys.exit(-1)\n",
    "    \n",
    "    return regr"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
